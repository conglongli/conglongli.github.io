---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I’m currently a Senior Researcher at [Microsoft DeepSpeed team](https://www.microsoft.com/en-us/research/project/deepspeed/), working on improving performance and efficiency of deep learning training and inference ([deepspeed.ai](https://www.deepspeed.ai/), [github repo](https://github.com/microsoft/DeepSpeed)). In general, I work on improving performance and resource efficiency of all kinds of computer systems via experimental research, data analysis, and algorithm/policy optimizations. My broad research interests lead to experience and publications in many areas including deep learning, similarity search, distributed caching systems, networks, and computer architecture.

I received Ph.D. in Computer Science from [Carnegie Mellon University](https://www.cmu.edu/) in 2020, advised by [Professor David G. Andersen](https://www.cs.cmu.edu/~dga/). I received both B.S. (2013) and M.S. (2014) in Computer Science from [Rice University](https://www.rice.edu/), advised by [Professor Alan L. Cox](https://profiles.rice.edu/faculty/alan-l-cox) and supported by the Graduate Research Fellowship.

Publications
======
1. [Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training.](paper/cl-arxiv.pdf)
  * **Conglong Li**, Minjia Zhang, Yuxiong He.
  * *[arXiv preprint arXiv:2108.06084](https://arxiv.org/abs/2108.06084).* \[[tutorial](https://www.deepspeed.ai/tutorials/curriculum-learning/)\]
1. [1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB's Convergence Speed.](paper/1bitlamb-arxiv.pdf)
  * **Conglong Li**, Ammar Ahmad Awan, Hanlin Tang, Samyam Rajbhandari, Yuxiong He.
  * *[arXiv preprint arXiv:2104.06069](https://arxiv.org/abs/2104.06069).* \[[tutorial](https://www.deepspeed.ai/tutorials/onebit-lamb/)\]
1. [1-bit Adam: Communication Efficient Large-Scale Training with Adam’s Convergence Speed.](paper/1bitadam-icml2021.pdf)
  * Hanlin Tang, Shaoduo Gan, Ammar Ahmad Awan, Samyam Rajbhandari, **Conglong Li**, Xiangru Lian, Ji Liu, Ce Zhang, Yuxiong He.
  * In *[ICML 2021](http://proceedings.mlr.press/v139/tang21a.html).* \[[tutorial](https://www.deepspeed.ai/tutorials/onebit-adam/)\]
1. [Learned Adaptive Accuracy-Cost Optimization for Machine Learning Systems.](paper/thesis-2020.pdf)
  * **Conglong Li**.
  * *[Ph.D. Thesis](http://reports-archive.adm.cs.cmu.edu/anon/2020/abstracts/20-105.html).*
1. [Improving Approximate Nearest Neighbor Search through Learned Adaptive Early Termination.](paper/ann-sigmod2020.pdf)
  * **Conglong Li**, Minjia Zhang, David G. Andersen, Yuxiong He.
  * In *[ACM SIGMOD 2020](https://dl.acm.org/doi/abs/10.1145/3318464.3380600).* [[source code](https://github.com/efficient/faiss-learned-termination)]
1. [Scaling Video Analytics on Constrained Edge Nodes.](paper/filterforward-sysml2019.pdf)
  * Christopher Canel, Thomas Kim, Giulio Zhou, **Conglong Li**, Hyeontaek Lim, David G. Andersen, Michael Kaminsky, Subramanya R. Dulloor.
  * In *[SysML 2019](https://mlsys.org/Conferences/2019/).* (This conference was renamed to MLSys from 2020.) [[source code](https://github.com/viscloud/ff)]
1. [Better Caching in Search Advertising Systems with Rapid Refresh Predictions.](paper/adscache-www2018.pdf)
  * **Conglong Li**, David G. Andersen, Qiang Fu, Sameh Elnikety, Yuxiong He.
  * In *[WWW 2018](https://dl.acm.org/doi/abs/10.1145/3178876.3186176).*
1. [Workload Analysis and Caching Strategies for Search Advertising Systems.](paper/adscache-socc2017.pdf)
  * **Conglong Li**, David G. Andersen, Qiang Fu, Sameh Elnikety, Yuxiong He.
  * In *[ACM SoCC 2017](https://dl.acm.org/doi/abs/10.1145/3127479.3129255).*
1. [Using Indirect Routing to Recover from Network Traffic Scheduling Estimation Error.](paper/albedo-ancs2017.pdf)
  * **Conglong Li**, Matthew K. Mukerjee, David G. Andersen, Srinivasan Seshan, Michael Kaminsky, George Porter, Alex C. Snoeren.
  * In *[ACM/IEEE ANCS 2017](https://ieeexplore.ieee.org/abstract/document/7966896).*
1. [Scheduling Techniques for Hybrid Circuit/Packet Networks.](paper/solstice-conext2015.pdf)
  * He Liu, Matthew K. Mukerjee, **Conglong Li**, Nicolas Feltman, George Papen, Stefan Savage, Srinivasan Seshan, Geoffrey M. Voelker, David G. Andersen, Michael Kaminsky, George Porter, Alex C. Snoeren.
  * In *[ACM CoNEXT 2015](https://dl.acm.org/doi/abs/10.1145/2716281.2836126).*
1. [GD-Wheel: A Cost-Aware Replacement Policy for Key-Value Stores.](paper/gdwheel-eurosys2015.pdf)
  * **Conglong Li**, Alan L. Cox.
  * In *[ACM EuroSys 2015](https://dl.acm.org/doi/abs/10.1145/2741948.2741956).*
1. [Reducing DRAM Row Activations with Eager Read/Write Clustering.](paper/writeback-taco2013.pdf)
  * Myeongjae Jeon, **Conglong Li**, Alan L. Cox, Scott Rixner.
  * In *[ACM TACO 2013](https://dl.acm.org/doi/abs/10.1145/2541228.2555300).*
1. [GD-Wheel: A Cost-Aware Replacement Policy for Key-Value Stores.](paper/gdwheel-ladis2013.pdf)
  * **Conglong Li**, Alan L. Cox.
  * In *7th Workshop on Large-Scale Distributed Systems and Middleware (LADIS 2013).*

Last updated: 2021/12/28

